
<!DOCTYPE html>

<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<link href="../distributed_training/" rel="prev"/>
<link href="../../s10_extra/" rel="next"/>
<link href="../../figures/favicon.png" rel="icon"/>
<meta content="mkdocs-1.4.2, mkdocs-material-9.1.6" name="generator"/>
<title>M29 - Scalable Inference - DTU-MLOps</title>
<link href="../../assets/stylesheets/main.ded33207.min.css" rel="stylesheet"/>
<link href="../../assets/stylesheets/palette.a0c5b2b5.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
<script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
<link href="../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
            html.glightbox-open { overflow: initial; height: 100%; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            
                .gscrollbar-fixer { padding-right: 15px; }
                .gdesc-inner { font-size: 0.75rem; }
                body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
                body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
                body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}
                </style><script src="../../assets/javascripts/glightbox.min.js"></script></head>
<body data-md-color-accent="" data-md-color-primary="light-blue" data-md-color-scheme="default" dir="ltr">
<script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#scalable-inference">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header md-header--shadow" data-md-component="header">
<nav aria-label="Header" class="md-header__inner md-grid">
<a aria-label="DTU-MLOps" class="md-header__button md-logo" data-md-component="logo" href="../.." title="DTU-MLOps">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"></path></svg>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            DTU-MLOps
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              M29 - Scalable Inference
            
          </span>
</div>
</div>
</div>
<form class="md-header__option" data-md-component="palette">
<input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="" data-md-color-media="" data-md-color-primary="light-blue" data-md-color-scheme="default" id="__palette_1" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_2" hidden="" title="Switch to dark mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
</label>
<input aria-label="Switch to light mode" class="md-option" data-md-color-accent="" data-md-color-media="" data-md-color-primary="indigo" data-md-color-scheme="slate" id="__palette_2" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to light mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
</label>
</form>
<label class="md-header__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="Search" required="" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg>
</label>
<nav aria-label="Search" class="md-search__options">
<button aria-label="Clear" class="md-search__icon md-icon" tabindex="-1" title="Clear" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"></path></svg>
</button>
</nav>
<div class="md-search__suggest" data-md-component="search-suggest"></div>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            Initializing search
          </div>
<ol class="md-search-result__list" role="presentation"></ol>
</div>
</div>
</div>
</div>
</div>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/SkafteNicki/dtu_mlops" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="DTU-MLOps" class="md-nav__button md-logo" data-md-component="logo" href="../.." title="DTU-MLOps">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"></path></svg>
</a>
    DTU-MLOps
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/SkafteNicki/dtu_mlops" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../..">
        Home
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../timeplan/">
        Timeplan
      </a>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_3" type="checkbox"/>
<div class="md-nav__link md-nav__link--index">
<a href="../../s1_development_environment/">S1 - Development Environment üíª</a>
<label for="__nav_3">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_3_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_3">
<span class="md-nav__icon md-icon"></span>
          S1 - Development Environment üíª
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../s1_development_environment/terminal/">
        M1 - Terminal
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../s1_development_environment/conda/">
        M2 - Conda
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../s1_development_environment/editor/">
        M3 - Editor
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../s1_development_environment/deep_learning_software/">
        M4 - Deep Learning Software
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_4" type="checkbox"/>
<div class="md-nav__link md-nav__link--index">
<a href="../../s2_organisation_and_version_control/">S2 - Organisation and Version Control üìÅ</a>
<label for="__nav_4">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_4_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_4">
<span class="md-nav__icon md-icon"></span>
          S2 - Organisation and Version Control üìÅ
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../s2_organisation_and_version_control/git/">
        M5 - Git
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../s2_organisation_and_version_control/code_structure/">
        M6 - Code structure
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../s2_organisation_and_version_control/good_coding_practice/">
        M7 - Good coding practice
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../s2_organisation_and_version_control/dvc/">
        M8 - Data version control
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_5" type="checkbox"/>
<div class="md-nav__link md-nav__link--index">
<a href="../../s3_reproducibility/">S3 - Reproduceability ‚ôªÔ∏è</a>
<label for="__nav_5">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_5_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_5">
<span class="md-nav__icon md-icon"></span>
          S3 - Reproduceability ‚ôªÔ∏è
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../s3_reproducibility/docker/">
        M9 - Docker
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../s3_reproducibility/config_files/">
        M10 - Config Files
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_6" type="checkbox"/>
<div class="md-nav__link md-nav__link--index">
<a href="../../s4_debugging_and_logging/">S4 - Debugging, Profiling and Logging ‚è±Ô∏è</a>
<label for="__nav_6">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_6_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_6">
<span class="md-nav__icon md-icon"></span>
          S4 - Debugging, Profiling and Logging ‚è±Ô∏è
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../s4_debugging_and_logging/debugging/">
        M11 - Debugging
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../s4_debugging_and_logging/profiling/">
        M12 - Profiling
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../s4_debugging_and_logging/logging/">
        M13 - Good Coding practice
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../s4_debugging_and_logging/boilerplate/">
        M14 - Data Version control
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_7" type="checkbox"/>
<div class="md-nav__link md-nav__link--index">
<a href="../../s5_continuous_integration/">S5 - Continues Integration ‚úîÔ∏è</a>
<label for="__nav_7">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_7_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_7">
<span class="md-nav__icon md-icon"></span>
          S5 - Continues Integration ‚úîÔ∏è
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../s5_continuous_integration/unittesting/">
        M15 - Unittesting
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../s5_continuous_integration/github_actions/">
        M16 - Github Actions
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../s5_continuous_integration/pre_commit/">
        M17 - Pre commit
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../s5_continuous_integration/auto_docker/">
        M18 - Continues Containers
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../s5_continuous_integration/cml/">
        M19 - Continues Machine Learning
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_8" type="checkbox"/>
<div class="md-nav__link md-nav__link--index">
<a href="../../s6_the_cloud/">S6 - The cloud üåê</a>
<label for="__nav_8">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_8_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_8">
<span class="md-nav__icon md-icon"></span>
          S6 - The cloud üåê
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../s6_the_cloud/cloud_setup/">
        M20 - Cloud Setup
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../s6_the_cloud/using_the_cloud/">
        M21 - Using the Cloud
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_9" type="checkbox"/>
<div class="md-nav__link md-nav__link--index">
<a href="../../s7_deployment/">S7 - Deployment üì¶</a>
<label for="__nav_9">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_9_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_9">
<span class="md-nav__icon md-icon"></span>
          S7 - Deployment üì¶
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../s7_deployment/apis/">
        M22 - Requests and APIs
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../s7_deployment/local_deployment/">
        M23 - Local Deployment
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../s7_deployment/cloud_deployment/">
        M24 - Cloud Deployment
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_10" type="checkbox"/>
<div class="md-nav__link md-nav__link--index">
<a href="../../s8_monitoring/">S8 - Monitoring üìä</a>
<label for="__nav_10">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_10_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_10">
<span class="md-nav__icon md-icon"></span>
          S8 - Monitoring üìä
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../s8_monitoring/data_drifting/">
        M25 - Data Drifting
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../s8_monitoring/monitoring/">
        M26 - System Monitoring
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_11" type="checkbox"/>
<div class="md-nav__link md-nav__link--index">
<a href="../">S9 - Scalable applications ‚öñÔ∏è</a>
<label for="__nav_11">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="true" aria-labelledby="__nav_11_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_11">
<span class="md-nav__icon md-icon"></span>
          S9 - Scalable applications ‚öñÔ∏è
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../data_loading/">
        M27 - Distributed Data Loading
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../distributed_training/">
        M28 - Distributed Training
      </a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
          M29 - Scalable Inference
          <span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="./">
        M29 - Scalable Inference
      </a>
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#choosing-the-right-architecture">
    Choosing the right architecture
  </a>
<nav aria-label="Choosing the right architecture" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#exercises">
    Exercises
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#quantization">
    Quantization
  </a>
<nav aria-label="Quantization" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#exercises_1">
    Exercises
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#pruning">
    Pruning
  </a>
<nav aria-label="Pruning" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#exercises_2">
    Exercises
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#knowledge-distillation">
    Knowledge distillation
  </a>
<nav aria-label="Knowledge distillation" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#exercises_3">
    Exercises
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_12" type="checkbox"/>
<div class="md-nav__link md-nav__link--index">
<a href="../../s10_extra/">S10 - Extra üî•</a>
<label for="__nav_12">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_12_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_12">
<span class="md-nav__icon md-icon"></span>
          S10 - Extra üî•
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../s10_extra/cli/">
        M30 - Command Line Interfaces
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../s10_extra/hyperparameters/">
        M31 - Hyperparameter optimization
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../s10_extra/high_performance_clusters/">
        M32 - High Performance Clusters
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../projects/">
        Projects
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../challenges/">
        Challenges
      </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#choosing-the-right-architecture">
    Choosing the right architecture
  </a>
<nav aria-label="Choosing the right architecture" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#exercises">
    Exercises
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#quantization">
    Quantization
  </a>
<nav aria-label="Quantization" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#exercises_1">
    Exercises
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#pruning">
    Pruning
  </a>
<nav aria-label="Pruning" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#exercises_2">
    Exercises
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#knowledge-distillation">
    Knowledge distillation
  </a>
<nav aria-label="Knowledge distillation" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#exercises_3">
    Exercises
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<p><a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="100%" href="../../figures/icons/pytorch.png"><img align="right" alt="Logo" src="../../figures/icons/pytorch.png" width="130"/></a></p>
<h1 id="scalable-inference">Scalable Inference</h1>
<hr/>
<p>Inference is task of applying our trained model to some new and unseen data, often called <em>prediction</em>. Thus, scaling
inference is different from scaling data loading and training, mainly due to inference normally only using a single
data point (or a few). As we can neither parallelize the data loading or parallelize using multiple GPUs (at least
not in any efficient way), this is of no use to us when we are doing inference. Secondly, inference is often not
something we do on machines that can perform large computations, as most inference today is actually either done on
<em>edge</em> devices e.g. mobile phones or in low-cost-low-compute cloud environments. Thus, we need to be smarter about how
we scale inference than just throwing more compute at it.</p>
<p>In this module we are going to look at various ways that you can either reduce the size of your model and or make your
model faster. Both are important for running inference fast regardless of the setup you are running your model on. We
want to note that this is still very much an active area of research and therefore best practices for what to do in a
specific situation can change.</p>
<h2 id="choosing-the-right-architecture">Choosing the right architecture</h2>
<p>Assume you are starting a completely new project and have to come up with a model architecture for doing this. What is
you strategy? The common way to do this, is to look at prior work on similar problems that you are facing and either
directly choosing the same architecture or creating some slight variation hereof. This is a great way to get started,
but the architecture that you end up choosing may be optimal in terms of performance but not inference speed.</p>
<p>The fact is that not all base architectures are created equal, and a 10K parameter model with one architecture can have
significantly different inference speed than another 10K parameter model with another architecture. For example,
consider the figure below which compares a number of models from the [timm] package, colored based on their base
architecture. The general trend is that the number of images that can be processed by a model per sec (y-axis) is
inverse proportional to the number of parameters (x-axis). However, we in general see that convolutional base
architectures (conv) are more efficient than transformer (vit) for the same parameter budget.</p>
<figure>
<p><a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="100%" href="../../figures/infer_param_count.jpg"><img alt="Image" src="../../figures/infer_param_count.jpg" width="800"/></a></p>
<figcaption> <a href="https://twitter.com/wightmanr/status/1453060491970953217"> Image credit </a> </figcaption>
</figure>
<h3 id="exercises">Exercises</h3>
<p>As dissed in this
<a href="https://devblog.pytorchlightning.ai/training-an-edge-optimized-speech-recognition-model-with-pytorch-lightning-a0a6a0c2a413">blogpost</a>
the largest increase in inference speed you will see (given some speficic hardware) is choosing an efficient model
architechture. In the exercises below we are going to investigate the inference speed of different architechtures.</p>
<ol>
<li>
<p>Start by checking out this
    <a href="https://pytorch.org/vision/stable/models.html#table-of-all-available-classification-weights">table</a>
    which contains a list of pretrained weights in <code>torchvision</code>. Try finding an</p>
<ul>
<li>Efficientnet</li>
<li>Resnet</li>
<li>Transformer based</li>
</ul>
<p>model that have in the range of 20-30 mio parameters.</p>
</li>
<li>
<p>Write a small script that initialize all models and does inference with them. It should look something like this</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="kn">import</span> <span class="nn">time</span>
</span><span id="__span-0-2"><a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">models</span>
</span><span id="__span-0-3"><a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a>
</span><span id="__span-0-4"><a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="n">m1</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">ModelArchitechture1</span><span class="p">()</span>
</span><span id="__span-0-5"><a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="n">m2</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">ModelArchitechture2</span><span class="p">()</span>
</span><span id="__span-0-6"><a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="n">m3</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">ModelArchitechture3</span><span class="p">()</span>
</span><span id="__span-0-7"><a href="#__codelineno-0-7" id="__codelineno-0-7" name="__codelineno-0-7"></a>
</span><span id="__span-0-8"><a href="#__codelineno-0-8" id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
</span><span id="__span-0-9"><a href="#__codelineno-0-9" id="__codelineno-0-9" name="__codelineno-0-9"></a>
</span><span id="__span-0-10"><a href="#__codelineno-0-10" id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="n">m1</span><span class="p">,</span> <span class="n">m2</span><span class="p">,</span> <span class="n">m3</span><span class="p">]):</span>
</span><span id="__span-0-11"><a href="#__codelineno-0-11" id="__codelineno-0-11" name="__codelineno-0-11"></a>    <span class="n">tic</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</span><span id="__span-0-12"><a href="#__codelineno-0-12" id="__codelineno-0-12" name="__codelineno-0-12"></a>    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_reps</span><span class="p">):</span>
</span><span id="__span-0-13"><a href="#__codelineno-0-13" id="__codelineno-0-13" name="__codelineno-0-13"></a>        <span class="n">_</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</span><span id="__span-0-14"><a href="#__codelineno-0-14" id="__codelineno-0-14" name="__codelineno-0-14"></a>    <span class="n">toc</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</span><span id="__span-0-15"><a href="#__codelineno-0-15" id="__codelineno-0-15" name="__codelineno-0-15"></a>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Model </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> took: </span><span class="si">{</span><span class="p">(</span><span class="n">toc</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">tic</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">n_reps</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</span></code></pre></div>
</li>
<li>
<p>Does the results make sense? Based on the above figure we would expect that efficientnet is faster than resnet,
    which is faster than the transformer based model. Is this also what you are seeing?</p>
</li>
<li>
<p>To figure out why one net is more efficient than another we can try to count the operations each network need to
    do for inference. A operation here we can define as a
    <a href="https://en.wikipedia.org/wiki/FLOPS">FLOP (floating point operation)</a> which is any mathematical operation (such as
    +, -, *, /) or assignment that involves floating-point numbers. Luckily for us someone has already created a python
    package for calculating this in pytorch: <a href="https://github.com/sovrasov/flops-counter.pytorch">ptflops</a></p>
<ol>
<li>
<p>Install the package</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-1-1"><a href="#__codelineno-1-1" id="__codelineno-1-1" name="__codelineno-1-1"></a>pip<span class="w"> </span>install<span class="w"> </span>ptflops
</span></code></pre></div>
</li>
<li>
<p>Try calling the <code>get_model_complexity_info</code> function from the <code>ptflops</code> package on the networks from the
    previous exercise. What are the results?</p>
</li>
</ol>
</li>
<li>
<p>In the table from the initial exercise, you could also see the overall performance of each network on the
    Imagenet-1K dataset. Given this performance, the inference speed, the flops count what network would you choose
    to use in a production setting? Discuss when choosing one over another should be considered.</p>
</li>
</ol>
<h2 id="quantization">Quantization</h2>
<p>Quantization is a technique where all computations are performed with integers instead of floats.
We are essentially taking all continuous signals and converting them into discretized signals.</p>
<figure>
<p><a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="100%" href="../../figures/quantization.png"><img alt="Image" src="../../figures/quantization.png" width="300"/></a></p>
<figcaption> <a href="https://arxiv.org/abs/1910.01108v4"> Image credit </a> </figcaption>
</figure>
<p>As discussed in this
<a href="https://devblog.pytorchlightning.ai/benchmarking-quantized-mobile-speech-recognition-models-with-pytorch-lightning-and-grid-9a69f7503d07">blogpost series</a>,
while <code>float</code> (32-bit) is the primarily used precision in machine learning because is strikes a good balance between
memory consumption, precision and computational requirement it does not mean that during inference we can take
advantage of quantization to improve the speed of our model. For instance:</p>
<ul>
<li>
<p>Floating-point computations are slower than integer operations</p>
</li>
<li>
<p>Recent hardware have specialized hardware for doing integer operations</p>
</li>
<li>
<p>Many neural networks are actually not bottlenecked by how many computations they need to do but by how fast we can
    transfer data e.g. the memory bandwidth and cache of your system is the limiting factor. Therefore working with 8-bit
    integers vs 32-bit floats means that we can approximately move data around 4 times as fast.</p>
</li>
<li>
<p>Storing models in integers instead of floats save us approximately 75% of the ram/harddisk space whenever we save
    a checkpoint. This is especially useful in relation to deploying models using docker (as you hopefully remember) as
    it will lower the size of our docker images.</p>
</li>
</ul>
<p>But how do we convert between floats and integers in quantization? In most cases we often use a
<em>linear affine quantization</em>:</p>
<p>$$
x_{int} = \text{round}\left( \frac{x_{float}}{s} + z \right)
$$</p>
<p>where $s$ is a scale and $z$ is the so called zero point. But how does to doing inference in a neural network. The
figure below shows all the conversations that we need to make to our standard inference pipeline to actually do
computations in quantized format.</p>
<!-- markdownlint-disable -->
<figure>
<p><a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="100%" href="../../figures/quantization_overview.png"><img alt="Image" src="../../figures/quantization_overview.png" width="600"/></a></p>
<figcaption>
<a href="https://devblog.pytorchlightning.ai/how-to-train-edge-optimized-speech-recognition-models-with-pytorch-lightning-part-2-quantization-2eaa676b1512"> Image credit </a>
</figcaption>
</figure>
<!-- markdownlint-restore -->
<h3 id="exercises_1">Exercises</h3>
<ol>
<li>
<p>Lets look at how quantized tensors look in Pytorch</p>
<ol>
<li>
<p>Start by creating a tensor that contains both random numbers</p>
</li>
<li>
<p>Next call the <code>torch.quantize_per_tensor</code> function on the tensor. What does the quantized tensor
    look like? How does the values relate to the <code>scale</code> and <code>zero_point</code> arguments.</p>
</li>
<li>
<p>Finally, try to call the <code>.dequantize()</code> method on the tensor. Do you get a tensor back that is
    close to what you initially started out with.</p>
</li>
</ol>
</li>
<li>
<p>As you hopefully saw in the first exercise we are going to perform a number of rounding errors when
    doing quantization and naively we would expect that this would accumulate and lead to a much worse model.
    However, in practice we observe that quantization still works, and we actually have a mathematically
    sound reason for this. Can you figure out why quantization still works with all the small rounding
    errors? HINT: it has to do with the <a href="https://en.wikipedia.org/wiki/Central_limit_theorem">central limit theorem</a></p>
</li>
<li>
<p>Lets move on to quantization of our model. Follow this
    <a href="https://pytorch.org/docs/stable/quantization.html">tutorial</a> from Pytorch on how to do quantization. The goal is
    to construct a model <code>model_fc32</code> that works on normal floats and a quantized version <code>model_int8</code>. For simplicity
    you can just use one of the models from the tutorial.</p>
</li>
<li>
<p>Lets try to benchmark our quantized model and see if all the trouble that we went through actually paid of. Also
    try to perform the benchmark on the non-quantized model and see if you get a difference. If you do not get an
    improvement, explain why that may be.</p>
</li>
</ol>
<h2 id="pruning">Pruning</h2>
<p>Pruning is another way for reducing the model size and maybe improve performance of our network. As the figure below
illustrates, in pruning we are simply removing weights in our network that we do not consider important for the task
at hand. By removing, we here mean that the weight gets set to 0. There are many ways to determine if a weight is
important but the general rule that the importance of a weight is proportional to the magnitude of a given weight. This
makes intuitively sense, since weights in all linear operations (fully connected or convolutional) are always
multiplied onto the incoming value, thus a small weight means a small outgoing activation.</p>
<figure>
<p><a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="100%" href="../../figures/pruning.png"><img alt="Image" src="../../figures/pruning.png" width="800"/></a></p>
<figcaption> <a href="https://kubernetes.io/docs/concepts/overview/components/"> Image credit </a> </figcaption>
</figure>
<h3 id="exercises_2">Exercises</h3>
<ol>
<li>
<p>We provide a start script that implements the famous
    <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf">LeNet</a> in this
    <a href="https://github.com/SkafteNicki/dtu_mlops/tree/main/s9_scalable_applications/exercise_files/lenet.py">file</a>.
    Open and run it just to make sure that you know the network.</p>
</li>
<li>
<p>Pytorch have already some pruning methods implemented in its package.
    Import the <code>prune</code> module from <code>torch.nn.utils</code> in the script.</p>
</li>
<li>
<p>Try to prune the weights of the first convolutional layer by calling</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-2-1"><a href="#__codelineno-2-1" id="__codelineno-2-1" name="__codelineno-2-1"></a><span class="n">prune</span><span class="o">.</span><span class="n">random_unstructured</span><span class="p">(</span><span class="n">module_1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"weight"</span><span class="p">,</span> <span class="n">amount</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
</span></code></pre></div>
<p>Try printing the <code>named_parameters</code>, <code>named_buffers</code> before and after the module is pruned. Can you explain the
difference and what is the connection to the <code>module_1.weight</code> attribute. Hint: You can read about the prune
method <a href="https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.random_unstructured.html#torch.nn.utils.prune.random_unstructured">here</a>.</p>
</li>
<li>
<p>Try pruning the bias of the same module this time using the <code>l1_unstructured</code> function from the pruning module. Again
    check the  <code>named_parameters</code>, <code>named_buffers</code> argument to make sure you understand the difference between L1 pruning
    and unstructured pruning.</p>
</li>
<li>
<p>Instead of pruning only a single module in the model lets try pruning the hole model. To do this we just need to
    iterate over all <code>named_modules</code> in the model like this:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-3-1"><a href="#__codelineno-3-1" id="__codelineno-3-1" name="__codelineno-3-1"></a><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">new_model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
</span><span id="__span-3-2"><a href="#__codelineno-3-2" id="__codelineno-3-2" name="__codelineno-3-2"></a>    <span class="n">prune</span><span class="o">.</span><span class="n">l1_unstructured</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'weight'</span><span class="p">,</span> <span class="n">amount</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</span></code></pre></div>
<p>But what if we wanted to apply different pruning to different layers. Implement a pruning scheme where</p>
<ul>
<li>The weights of convolutional layers are L1 pruned with <code>amount=0.2</code></li>
<li>The weights of linear layers are unstructured pruned with <code>amount=0.4</code></li>
</ul>
<p>Print <code>print(dict(new_model.named_buffers()).keys())</code> after the pruning to confirm that all weights have been
correctly pruned.</p>
</li>
<li>
<p>The pruning we have looked at until know have only been local in nature e.g. we have applied the pruning
    independently for each layer, not accounting globally for how much we should actually prune. As you may realize this
    can quickly lead to an network that is pruned too much. Instead, the more common approach is too prune globally
    where we remove the smallest <code>X</code> amount of connections:</p>
<ol>
<li>
<p>Start by creating a tuple over all the weights with the following format</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-4-1"><a href="#__codelineno-4-1" id="__codelineno-4-1" name="__codelineno-4-1"></a><span class="n">parameters_to_prune</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-4-2"><a href="#__codelineno-4-2" id="__codelineno-4-2" name="__codelineno-4-2"></a>    <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">conv1</span><span class="p">,</span> <span class="s1">'weight'</span><span class="p">),</span>
</span><span id="__span-4-3"><a href="#__codelineno-4-3" id="__codelineno-4-3" name="__codelineno-4-3"></a>    <span class="c1"># fill in the rest of the modules yourself</span>
</span><span id="__span-4-4"><a href="#__codelineno-4-4" id="__codelineno-4-4" name="__codelineno-4-4"></a>    <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc3</span><span class="p">,</span> <span class="s1">'weight'</span><span class="p">),</span>
</span><span id="__span-4-5"><a href="#__codelineno-4-5" id="__codelineno-4-5" name="__codelineno-4-5"></a><span class="p">)</span>
</span></code></pre></div>
<p>The tuple needs to have length 5. Challenge: Can you construct the tuple using <code>for</code> loops, such that the code
works for arbitrary size networks?</p>
</li>
<li>
<p>Next prune using the <code>global_unstructured</code> function to globally prune the tuple of parameters</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-5-1"><a href="#__codelineno-5-1" id="__codelineno-5-1" name="__codelineno-5-1"></a><span class="n">prune</span><span class="o">.</span><span class="n">global_unstructured</span><span class="p">(</span>
</span><span id="__span-5-2"><a href="#__codelineno-5-2" id="__codelineno-5-2" name="__codelineno-5-2"></a>    <span class="n">parameters_to_prune</span><span class="p">,</span>
</span><span id="__span-5-3"><a href="#__codelineno-5-3" id="__codelineno-5-3" name="__codelineno-5-3"></a>    <span class="n">pruning_method</span><span class="o">=</span><span class="n">prune</span><span class="o">.</span><span class="n">L1Unstructured</span><span class="p">,</span>
</span><span id="__span-5-4"><a href="#__codelineno-5-4" id="__codelineno-5-4" name="__codelineno-5-4"></a>    <span class="n">amount</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
</span><span id="__span-5-5"><a href="#__codelineno-5-5" id="__codelineno-5-5" name="__codelineno-5-5"></a><span class="p">)</span>
</span></code></pre></div>
</li>
<li>
<p>Check that the amount that have been pruned is actually equal to the 20% specified in the pruning. We provide
    the following function that for a given submodule (for example <code>model.conv1</code>) computes the amount of pruned
    weights</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-6-1"><a href="#__codelineno-6-1" id="__codelineno-6-1" name="__codelineno-6-1"></a><span class="k">def</span> <span class="nf">check_prune_level</span><span class="p">(</span><span class="n">module</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="__span-6-2"><a href="#__codelineno-6-2" id="__codelineno-6-2" name="__codelineno-6-2"></a>    <span class="n">sparsity_level</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="nb">float</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">weight</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">numel</span><span class="p">())</span>
</span><span id="__span-6-3"><a href="#__codelineno-6-3" id="__codelineno-6-3" name="__codelineno-6-3"></a>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Sparsity level of module </span><span class="si">{</span><span class="n">sparsity_level</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</span></code></pre></div>
</li>
</ol>
</li>
<li>
<p>With a pruned network we really want to see if all our effort actually ended up with a network that is faster and/or
    smaller in memory. Do the following to the globally pruned network from the previous exercises:</p>
<ol>
<li>
<p>First we need to make the pruning of our network permanent. Right now it is only semi-permanent as we are still
    keeping a copy of the original weights in memory. Make the change permanent by calling <code>prune.remove</code> on every
    pruned module in the model. Hint: iterate over the <code>parameters_to_prune</code> tuple.</p>
</li>
<li>
<p>Next try to measure the time of a single inference (repeated 100 times) for both the pruned and non-pruned network</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-7-1"><a href="#__codelineno-7-1" id="__codelineno-7-1" name="__codelineno-7-1"></a><span class="kn">import</span> <span class="nn">time</span>
</span><span id="__span-7-2"><a href="#__codelineno-7-2" id="__codelineno-7-2" name="__codelineno-7-2"></a><span class="n">tic</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</span><span id="__span-7-3"><a href="#__codelineno-7-3" id="__codelineno-7-3" name="__codelineno-7-3"></a><span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
</span><span id="__span-7-4"><a href="#__codelineno-7-4" id="__codelineno-7-4" name="__codelineno-7-4"></a>    <span class="n">_</span> <span class="o">=</span> <span class="n">network</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span>
</span><span id="__span-7-5"><a href="#__codelineno-7-5" id="__codelineno-7-5" name="__codelineno-7-5"></a><span class="n">toc</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</span><span id="__span-7-6"><a href="#__codelineno-7-6" id="__codelineno-7-6" name="__codelineno-7-6"></a><span class="nb">print</span><span class="p">(</span><span class="n">toc</span> <span class="o">-</span> <span class="n">tic</span><span class="p">)</span>
</span></code></pre></div>
<p>Is the pruned network actually faster? If not can you explain why?</p>
</li>
<li>
<p>Next lets measure the size of our network (called <code>pruned_network</code>) and a freshly initialized network (called
    <code>network</code>):</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-8-1"><a href="#__codelineno-8-1" id="__codelineno-8-1" name="__codelineno-8-1"></a><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">pruned_network</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">'pruned_network.pt'</span><span class="p">)</span>
</span><span id="__span-8-2"><a href="#__codelineno-8-2" id="__codelineno-8-2" name="__codelineno-8-2"></a><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">'network.pt'</span><span class="p">)</span>
</span></code></pre></div>
<p>Lookup the size of each file. Are the pruned network actually smaller? If not can you explain why?</p>
</li>
<li>
<p>Repeat the last exercise, but this time start by converting all pruned weights to sparse format first by calling
    the <code>.to_sparse()</code> method on each pruned weight. Is the saved model smaller now?</p>
</li>
</ol>
</li>
</ol>
<p>This ends the exercises on pruning. As you probably realized in the last couple of exercises, then pruning does not
guarantee speedups out of the box. This is because linear operations in Pytorch does not handle sparse structures out
of the box. To actually get speedups we would need to deep dive into the
<a href="https://pytorch.org/docs/stable/sparse.html">sparse tensor operations</a>, which again does not even guarantee that a
speedup because the performance of these operations depends on the sparsity structure of the pruned weights.
Investigating this is out of scope for these exercises, but we highly recommend checking it out if you are interested
in sparse networks.</p>
<h2 id="knowledge-distillation">Knowledge distillation</h2>
<p>Knowledge distillation is somewhat similar to pruning, in the sense that it tries to find a smaller model that can
perform equally well as a large model, however it does so in a completly different way. Knowledge distillation is a
<em>model compression</em> technique that builds on the work of
<a href="https://www.cs.cornell.edu/~caruana/compression.kdd06.pdf">Bucila et al.</a> in which we try do distill/compress the
knowledge of a large complex model (also called the teacher model) into a simpler model (also called the student model).</p>
<p>The best known example of this is the <a href="https://arxiv.org/abs/1910.01108">DistilBERT model</a>. The DistilBERT model is a
smaller version of the large natural-language procession model Bert, which achives 97% of the performance of Bert while
only containing 40% of the weights and being 60% faster. You can see in the figure below how it is much smaller in size
compared to other models developed at the same time.</p>
<figure>
<p><a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="100%" href="../../figures/distill.png"><img alt="Image" src="../../figures/distill.png" width="800"/></a></p>
<figcaption> <a href="https://arxiv.org/pdf/1910.01108.pdf"> Image credit </a> </figcaption>
</figure>
<p>Knowledge distillation works by assuming we have a big teacher that is already performing well that we want to compress.
By runnning our training set through our large model we get a softmax distribution for each and every training sample.
The goal of the students, is to both match the original labels of the training data but also match the softmax
distribution of the teacher model. The intuition behind doing this, is that teacher model needs to be more complex to
learn the complex inter-class relasionship from just (one-hot) labels. The student on the other hand gets directly feed
with softmax distributions from the teacher that explicit encodes this inter-class relasionship and thus does not need
the same capasity to learn the same as the teacher.</p>
<figure>
<p><a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="100%" href="../../figures/knowledge_distillation.png"><img alt="Image" src="../../figures/knowledge_distillation.png" width="800"/></a></p>
<figcaption> <a href="https://deeplearningsystems.ai/#ch06/"> Image credit </a> </figcaption>
</figure>
<h3 id="exercises_3">Exercises</h3>
<p>Lets try implementing model distillation ourself. We are going to see if we can achive this on the
<a href="https://www.cs.toronto.edu/~kriz/cifar.html">cifar10</a> dataset. Do note that exercise below can take quite long time to
finish because it involves training multiple networks and therefore involve some waiting.</p>
<ol>
<li>
<p>Start by install the <code>transformers</code> and <code>datasets</code> packages from Huggingface</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-9-1"><a href="#__codelineno-9-1" id="__codelineno-9-1" name="__codelineno-9-1"></a>pip<span class="w"> </span>install<span class="w"> </span>transformers
</span><span id="__span-9-2"><a href="#__codelineno-9-2" id="__codelineno-9-2" name="__codelineno-9-2"></a>pip<span class="w"> </span>install<span class="w"> </span>datasets
</span></code></pre></div>
<p>which we are going to download the cifar10 dataset and a teacher model.</p>
</li>
<li>
<p>Next download the cifar10 dataset</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-10-1"><a href="#__codelineno-10-1" id="__codelineno-10-1" name="__codelineno-10-1"></a><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
</span><span id="__span-10-2"><a href="#__codelineno-10-2" id="__codelineno-10-2" name="__codelineno-10-2"></a><span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">"cifar10"</span><span class="p">)</span>
</span></code></pre></div>
</li>
<li>
<p>Next lets initialize our teacher model. For this we consider a large transformer based model:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-11-1"><a href="#__codelineno-11-1" id="__codelineno-11-1" name="__codelineno-11-1"></a><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoFeatureExtractor</span><span class="p">,</span> <span class="n">AutoModelForImageClassification</span>
</span><span id="__span-11-2"><a href="#__codelineno-11-2" id="__codelineno-11-2" name="__codelineno-11-2"></a><span class="n">extractor</span> <span class="o">=</span> <span class="n">AutoFeatureExtractor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"aaraki/vit-base-patch16-224-in21k-finetuned-cifar10"</span><span class="p">)</span>
</span><span id="__span-11-3"><a href="#__codelineno-11-3" id="__codelineno-11-3" name="__codelineno-11-3"></a><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForImageClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"aaraki/vit-base-patch16-224-in21k-finetuned-cifar10"</span><span class="p">)</span>
</span></code></pre></div>
</li>
<li>
<p>To get the logits (un-normalized softmax scores) from our teacher model for a single datapoint from the training
    dataset you would extract it like this:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-12-1"><a href="#__codelineno-12-1" id="__codelineno-12-1" name="__codelineno-12-1"></a><span class="n">sample_img</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">'train'</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">'img'</span><span class="p">]</span>
</span><span id="__span-12-2"><a href="#__codelineno-12-2" id="__codelineno-12-2" name="__codelineno-12-2"></a><span class="n">preprocessed_img</span> <span class="o">=</span> <span class="n">extractor</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">'train'</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">'img'</span><span class="p">],</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s1">'pt'</span><span class="p">)</span>
</span><span id="__span-12-3"><a href="#__codelineno-12-3" id="__codelineno-12-3" name="__codelineno-12-3"></a><span class="n">output</span> <span class="o">=</span>  <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">preprocessed_img</span><span class="p">)</span>
</span><span id="__span-12-4"><a href="#__codelineno-12-4" id="__codelineno-12-4" name="__codelineno-12-4"></a><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">logits</span><span class="p">)</span>
</span><span id="__span-12-5"><a href="#__codelineno-12-5" id="__codelineno-12-5" name="__codelineno-12-5"></a><span class="c1"># tensor([[ 3.3682, -0.3160, -0.2798, -0.5006, -0.5529, -0.5625, -0.6144, -0.4671, 0.2807, -0.3066]])</span>
</span></code></pre></div>
<p>Repeat this process for the hole training dataset and store the result somewhere.</p>
</li>
<li>
<p>Implement a simple convolutional model. You can create a custom one yourself or use a small one from <code>torchvision</code>.</p>
</li>
<li>
<p>Train the model on cifar10 to convergence, so you have a base result on how the model is performing.</p>
</li>
<li>
<p>Redo the training, but this time add knowledge distillation to your training objective. It should look like this:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-13-1"><a href="#__codelineno-13-1" id="__codelineno-13-1" name="__codelineno-13-1"></a><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
</span><span id="__span-13-2"><a href="#__codelineno-13-2" id="__codelineno-13-2" name="__codelineno-13-2"></a>    <span class="c1"># ...</span>
</span><span id="__span-13-3"><a href="#__codelineno-13-3" id="__codelineno-13-3" name="__codelineno-13-3"></a>    <span class="n">img</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">teacher_logits</span> <span class="o">=</span> <span class="n">batch</span>
</span><span id="__span-13-4"><a href="#__codelineno-13-4" id="__codelineno-13-4" name="__codelineno-13-4"></a>    <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</span><span id="__span-13-5"><a href="#__codelineno-13-5" id="__codelineno-13-5" name="__codelineno-13-5"></a>    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
</span><span id="__span-13-6"><a href="#__codelineno-13-6" id="__codelineno-13-6" name="__codelineno-13-6"></a>    <span class="n">loss_teacher</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">teacher_logits</span><span class="p">)</span>
</span><span id="__span-13-7"><a href="#__codelineno-13-7" id="__codelineno-13-7" name="__codelineno-13-7"></a>    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">+</span> <span class="n">loss_teacher</span>
</span><span id="__span-13-8"><a href="#__codelineno-13-8" id="__codelineno-13-8" name="__codelineno-13-8"></a>    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span><span id="__span-13-9"><a href="#__codelineno-13-9" id="__codelineno-13-9" name="__codelineno-13-9"></a>    <span class="c1"># ...</span>
</span></code></pre></div>
</li>
<li>
<p>Compare the final performance obtained with and without knowledge distillation. Did the performance improve or not?</p>
</li>
</ol>
<p>This ends the module on scaling inference in machine learning models.</p>
<hr/>
<div class="md-source-file">
<small>
    
      Last update:
      <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">April 19, 2023</span>
<br/>
        Created:
        <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">April 19, 2023</span>
</small>
</div>
</article>
</div>
</div>
</main>
<footer class="md-footer">
<nav aria-label="Footer" class="md-footer__inner md-grid">
<a aria-label="Previous: M28 - Distributed Training" class="md-footer__link md-footer__link--prev" href="../distributed_training/" rel="prev">
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg>
</div>
<div class="md-footer__title">
<span class="md-footer__direction">
                Previous
              </span>
<div class="md-ellipsis">
                M28 - Distributed Training
              </div>
</div>
</a>
<a aria-label="Next: Extra learning modules" class="md-footer__link md-footer__link--next" href="../../s10_extra/" rel="next">
<div class="md-footer__title">
<span class="md-footer__direction">
                Next
              </span>
<div class="md-ellipsis">
                Extra learning modules
              </div>
</div>
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"></path></svg>
</div>
</a>
</nav>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs
    </a>
</div>
<div class="md-social">
<a class="md-social__link" href="mailto:skaftenicki@gmail.com" rel="noopener" target="_blank" title="">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m20 8-8 5-8-5V6l8 5 8-5m0-2H4c-1.11 0-2 .89-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2Z"></path></svg>
</a>
<a class="md-social__link" href="https://github.com/SkafteNicki" rel="noopener" target="_blank" title="github.com">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg>
</a>
<a class="md-social__link" href="https://www.linkedin.com/in/nicki-skafte-detlefsen/" rel="noopener" target="_blank" title="www.linkedin.com">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": "../..", "features": ["navigation.instant", "navigation.expand", "navigation.indexes", "content.code.copy", "navigation.footer", "search.suggest", "search.highlight"], "search": "../../assets/javascripts/workers/search.208ed371.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
<script src="../../assets/javascripts/bundle.51198bba.min.js"></script>
<script>document$.subscribe(() => {const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});})</script></body>
</html>